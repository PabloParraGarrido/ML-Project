{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFfjKJxjZPkY"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q numerapi pandas pyarrow matplotlib lightgbm scikit-learn cloudpickle scipy==1.10.1\n",
        "\n",
        "# Inline plots\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCqFGCeUlCxu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-oYFHsEZJBF"
      },
      "outputs": [],
      "source": [
        "from numerapi import NumerAPI\n",
        "napi = NumerAPI()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# list the datasets and available versions\n",
        "all_datasets = napi.list_datasets()\n",
        "dataset_versions = list(set(d.split('/')[0] for d in all_datasets))\n",
        "\n",
        "# Set data version to one of the latest datasets\n",
        "DATA_VERSION = \"v4.3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8Ex5zu9ZlwT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# # download the feature metadata file\n",
        "napi.download_dataset(f\"{DATA_VERSION}/features.json\");\n",
        "\n",
        "# read the metadata and display\n",
        "feature_metadata = json.load(open(f\"{DATA_VERSION}/features.json\"))\n",
        "feature_sets = feature_metadata[\"feature_sets\"]\n",
        "\n",
        "small_feature_set = feature_sets[\"small\"]\n",
        "medium_feature_set = feature_sets[\"medium\"]\n",
        "\n",
        "# # Download the training data - this will take a few minutes\n",
        "napi.download_dataset(f\"{DATA_VERSION}/train_int8.parquet\");\n",
        "\n",
        "# Load only the \"small\" and \"medium\" feature set to\n",
        "# Use the \"all\" feature set to use all features\n",
        "small_data = pd.read_parquet(\n",
        "    f\"{DATA_VERSION}/train_int8.parquet\",\n",
        "    columns=[\"era\", \"target\"] + small_feature_set\n",
        ")\n",
        "medium_data = pd.read_parquet(\n",
        "    f\"{DATA_VERSION}/train_int8.parquet\",\n",
        "    columns=[\"era\", \"target\"] + medium_feature_set\n",
        ")\n",
        "\n",
        "# Downsample to every 4th era to reduce memory usage and speedup model training (suggested for Colab free tier)\n",
        "# Comment out the line below to use all the data\n",
        "small_data = small_data[small_data[\"era\"].isin(small_data[\"era\"].unique()[::4])]\n",
        "medium_data = medium_data[medium_data[\"era\"].isin(medium_data[\"era\"].unique()[::4])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPj3IlNPZrNR"
      },
      "outputs": [],
      "source": [
        "small_X_train = small_data[small_feature_set]\n",
        "small_y_train = small_data[\"target\"]\n",
        "medium_X_train = medium_data[medium_feature_set]\n",
        "medium_y_train = medium_data[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whE7NCVjBF1V",
        "outputId": "bc4b29d4-9704-4a8a-e20a-7737a8949fd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "feature_enzymatic_poorest_advocaat             -0.011773\n",
              "feature_unswaddled_inenarrable_goody           -0.011449\n",
              "feature_wetter_unbaffled_loma                  -0.007477\n",
              "feature_floatiest_quintuplicate_carpentering   -0.007150\n",
              "feature_unbarking_apolitical_hibernian         -0.007114\n",
              "                                                  ...   \n",
              "feature_hunchbacked_unturning_meditation        0.010299\n",
              "feature_denuded_typed_wattmeter                 0.010343\n",
              "feature_pruinose_raploch_roubaix                0.010585\n",
              "feature_leaky_overloaded_rhodium                0.011407\n",
              "feature_simpatico_cadential_pup                 0.012055\n",
              "Length: 705, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find correlation between features and outcome\n",
        "corr = medium_X_train.corrwith(medium_y_train)\n",
        "corr.sort_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlGCsC53InGN",
        "outputId": "7495a105-81a0-444d-fd9e-3ff6c69b096a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "feature_simpatico_cadential_pup         0.012055\n",
              "feature_enzymatic_poorest_advocaat      0.011773\n",
              "feature_unswaddled_inenarrable_goody    0.011449\n",
              "feature_leaky_overloaded_rhodium        0.011407\n",
              "feature_pruinose_raploch_roubaix        0.010585\n",
              "dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the most correlated features\n",
        "corr_sorted = abs(corr).sort_values(ascending=False).head()\n",
        "corr_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvu3f8O3K-4a"
      },
      "outputs": [],
      "source": [
        "# # get 100 most correlated features\n",
        "# medium100_feature_set = corr.columns # can't get it to work\n",
        "# medium100_X_train = medium_X_train[medium100_feature_set]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4c-eSBVJX5Z"
      },
      "outputs": [],
      "source": [
        "small_y_train = pd.Categorical(small_y_train).codes\n",
        "medium_y_train = pd.Categorical(medium_y_train).codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLpvanDmm72G"
      },
      "outputs": [],
      "source": [
        "# feature_set_sizes = {'small': [small_X_train,small_y_train], 'medium': [medium_X_train,medium_y_train], 'medium100': [medium100_X_train,medium_y_train]}\n",
        "feature_set_sizes = {'small': [small_X_train,small_y_train], 'medium': [medium_X_train,medium_y_train]}\n",
        "kernels = ['linear', 'poly', 'rbf']\n",
        "lambds = [1.0, 0.1, 0.01, 0.001, 0.0001]\n",
        "models = {}\n",
        "train_predictions = {}\n",
        "train_scores = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9u7XlUIuDv"
      },
      "source": [
        "Manually implemented SVM Pegasos algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfjh0GKgksc2"
      },
      "outputs": [],
      "source": [
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTIcmBKu1ddH"
      },
      "outputs": [],
      "source": [
        "# Our SVM algorithm Pegasos expects the labels to be encoded as +1 and -1\n",
        "# Here we encode one digit as 1, and we encode the other 9 digits as -1\n",
        "def one_vs_rest_encoding(y, outcome = 0):\n",
        "\n",
        "    # Let y_encoded be an numpy array of encoded digits, with 1 for the digit we want to predict, and -1 for the rest\n",
        "    # This may take several lines of code, but please store your final encoding in y_encoded\n",
        "\n",
        "    y_encoded = np.array([1 if label == outcome else -1 for label in y])\n",
        "\n",
        "    return  y_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuWlRACSizzE"
      },
      "outputs": [],
      "source": [
        "# Compute the score for each example in X\n",
        "def score(X, w): #keep\n",
        "    # To do\n",
        "    return np.dot(X,w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "260hNdUFi1dc"
      },
      "outputs": [],
      "source": [
        "def svm_objective(w, X, y, lambda1=.1): # keep\n",
        "    # To do. This part may require several lines of code.\n",
        "    # Store your answer in result.\n",
        "\n",
        "    result = (lambda1/2) * np.linalg.norm(w)**2 + np.sum([max(0, 1-y[i]*(np.dot(X.iloc[i],w))) for i in range(y.shape[0])])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZesrtBPi5Lo"
      },
      "outputs": [],
      "source": [
        "# stochastic sub-gradient descent\n",
        "def pegasos(X_train, y_train, lambda1=0.08, num_iters = 3): #keep\n",
        "\n",
        "    # Hyperparameters: threshold, lambda1\n",
        "\n",
        "    # parameters\n",
        "    N = X_train.shape[0]\n",
        "    d = X_train.shape[1]\n",
        "\n",
        "    t = 0\n",
        "    # Initial weight vector\n",
        "    w = np.ones((d,))\n",
        "\n",
        "    for iter in range(num_iters):\n",
        "        # Calculate and print the objective value\n",
        "        print('Iteration %d. J: %.6f' % (iter, svm_objective(w, X_train, y_train)))\n",
        "\n",
        "        for i in range (N):\n",
        "            t = t + 1\n",
        "            alpha = 1/(lambda1*t)\n",
        "            # Complete the following code to find w. This will require several lines of code.\n",
        "            if y_train[i]*(np.dot(w,X_train.iloc[i])) >= 1:\n",
        "                w = w - alpha*lambda1*w\n",
        "            else:\n",
        "                w = w - alpha*(lambda1*w - y_train[i]*X_train.iloc[i])\n",
        "\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ4zVj8ei7qs",
        "outputId": "d538ed00-d91d-4c1a-b3be-1ca59b1712ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0. J: 813205914.250000\n",
            "Iteration 1. J: 63830.941081\n",
            "Iteration 2. J: 62768.361842\n",
            "Iteration 0. J: 683528870.250000\n",
            "Iteration 1. J: 252368.872695\n",
            "Iteration 2. J: 251003.288436\n",
            "Iteration 0. J: 428009511.250000\n",
            "Iteration 1. J: 527623.472848\n",
            "Iteration 2. J: 525549.161246\n",
            "Iteration 0. J: 683285420.250000\n",
            "Iteration 1. J: 253893.738209\n",
            "Iteration 2. J: 251020.553854\n",
            "Iteration 0. J: 813100828.250000\n",
            "Iteration 1. J: 62657.819568\n",
            "Iteration 2. J: 62824.293958\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters - You will experiment with these in Step 3\n",
        "lambda1 = 0.1  # Regularization parameter\n",
        "num_iters = 3   # Number of iterations\n",
        "\n",
        "# A) Create the 10 classifiers\n",
        "labels = [0,1,2,3,4]\n",
        "w_vals= {}\n",
        "val_scores = {}\n",
        "\n",
        "for i in labels: # Modify\n",
        "    # Perform one-vs-rest for labels[i]\n",
        "    # To do: Relabel the y labels in the train set to either 1 or -1 using one_vs_rest_encoding\n",
        "    y_encoded = one_vs_rest_encoding(y_train, outcome=labels[i])\n",
        "\n",
        "    # To do: Train the Pegasos algorithm on X_train X_train and  y_encoded to get the weight vector\n",
        "    w_vals[i] = pegasos(X_train, y_encoded, lambda1=lambda1, num_iters = num_iters)\n",
        "\n",
        "    # Using the validation set, estimate accuracy for one-vs-rest classifier for labels[i]\n",
        "    # To do:  Relabel the y labels in the validation set to either 1 or -1 using one_vs_rest_encoding\n",
        "    y_encoded_val = one_vs_rest_encoding(y_val, outcome=labels[i])\n",
        "\n",
        "    # This section may require more than one line of code.\n",
        "    # To do: Calculate an accuracy for one-vs-rest classifier for labels[i]\n",
        "\n",
        "    val_scores[i] = score(X_val, w_vals[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db8CTyqHi_Ac",
        "outputId": "fe9af42d-bb79-4c57-e6b5-cd04234d549f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 : score: [-1.09015643 -0.98939912 -0.9769     ... -1.0409848  -1.04311839\n",
            " -1.03618421]\n",
            "1 : score: [-1.11572107 -0.96358153 -0.95828604 ... -1.01761975 -1.01535968\n",
            " -1.01246723]\n",
            "2 : score: [-0.48464472  0.693264   -0.28555513 ...  0.56222395  0.59235821\n",
            "  0.85890896]\n",
            "3 : score: [-1.07980191 -0.97543728 -0.99541497 ... -1.01859306 -1.0084035\n",
            " -1.0110485 ]\n",
            "4 : score: [-1.1045417  -0.99383677 -0.99228607 ... -1.04662122 -1.02662703\n",
            " -1.00696277]\n"
          ]
        }
      ],
      "source": [
        "# Check your work. With the proper amount of iterations, your values should range from 0.95 to 0.99\n",
        "for i in labels:\n",
        "     print(i,\": score:\", val_scores[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0SM16NJi_yi"
      },
      "outputs": [],
      "source": [
        "# B) Label Prediction for Each Validation Set Example\n",
        "# To do: Loop through each sample in the validation set and assign it a label based on the highest score.\n",
        "predictions = []\n",
        "for i in range(X_val.shape[0]):\n",
        "    last_score = -10e9\n",
        "    for key, score in val_scores.items():\n",
        "        if score[i] > last_score:\n",
        "            last_score = score[i]\n",
        "            last_key = key\n",
        "    predictions.append(last_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEiNRPUXjB_Q",
        "outputId": "ba1da556-bb23-4bd2-830d-7312c889270b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.4884703452462651\n"
          ]
        }
      ],
      "source": [
        "# C) Accuracy on Validation Set Using Predicted Labels\n",
        "# Initialize an array 'eval1' of length N (number of examples in the validation set)\n",
        "# 'eval1' will hold 1 for correctly predicted digits and 0 for incorrect predictions.\n",
        "# You may use more than one line of code if needed for the following tasks.\n",
        "\n",
        "# To do:  Compute 'eval1' based on the comparison of predicted and actual labels\n",
        "eval = np.zeros(y_val.shape[0])\n",
        "for i, predicted in enumerate(predictions):\n",
        "    if predicted == y_val[i]:\n",
        "        eval[i] = 1\n",
        "\n",
        "# To do: Calculate the accuracy on the validation set. It should be approximately 0.89.\n",
        "accuracy = np.sum(eval) / y_val.shape[0]\n",
        "\n",
        "print(\"Accuracy Score:\",accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "28db8345e30a34ab49d36421477d659f63c7ac05bb83410490a792cab9cefc1a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
